# LWP

LWP, 즉 Thread를 구현하기 위해 두 가지 방법에 대해 고민했다.

첫째는 proc 구조체를 그대로 활용하는 방안이다.

이 방법을 사용하면 basic operation 구현과 중간중간에 제대로 동작하는지 test가 가능하다는 장점이 있다. 다만 구현을 하다 보니 System call 및 scheduler와의 최적화에 있어서 단점이 많다는 것을 깨닫게 되었다. 따라서 이번 프로젝트에서는 두 번째 방법인 Thread 구조체를 새로 만들어 사용하였다.

Thread를 별도로 만들어 구현하게 되면 전체적으로 최적화를 진행하여야 하고, 전체 최적화가 다 되기 전까지는 중간 test가 어렵다는 단점이 있었지만, 최적화와 동시에 System call 및 scheduler와의 최적화 또한 진행할 수 있었으며, 좀 더 명시적으로 코드 구별이 가능해져 최적화에 있어 수월했다.



### Thread 구조체와 Context Switch

- `void tsched(void);`
- `void tyield(void);`
- `struct thread;`

우선 전체적인 설계를 보자면, 기존의 xv-6의 경우 Proc 구조체에 할당된 `context`, `tf`, `kstack`을 이용해 Context Switch를 실행하였다. 실행 단위를 Process 에서 Thread로 이양시키기 위해, 해당 value들을 새로 생성한 Thread 구조체에 할당해 주었다.

```c
// Per-process state
struct proc {
  uint sz;                     // Size of process memory (bytes)
  pde_t* pgdir;                // Page table
  // char *kstack;                ->moved to thread
  enum procstate state;        // Process state
  int pid;                     // Process ID
  struct proc *parent;         // Parent process
  // struct trapframe *tf;        ->moved to thread
  // struct context *context;     ->moved to thread
  // void *chan;                  ->moved to thread
  int killed;                  // If non-zero, have been killed
  struct file *ofile[NOFILE];  // Open files
  struct inode *cwd;           // Current directory
  char name[16];               // Process name (debugging)

  struct q_node p_node;        // process node for scheduling queue009

  //! for thread implementation-------
  struct q_node *t_node;       // current thread node
  int nrt;                     // number of runnable threads
  int nt;						// number of threads (RUNNABLE or SLEEPING)
  struct q_header tl;        // list of lwps
  struct blanktsb bl;
  //!=============================
};
```



```c
struct thread {
 thread_t tid;
 char *kstack;
 struct context *context;
 struct trapframe *tf;
 void *chan;
 enum procstate tstate;
 uint tsb;          // thread stack is from {tsb} to {tsb + 2*PGSIZE}
 void *ret_val;        // Return value of the thread
 struct q_node t_node;
 struct proc *master;
};
```





LWP 동작 방식에서 LWP들은 자신이 속한 Process가 스케쥴러에 의해 선택되어 졌을 때만 Time quantum 안에서 서로 번갈아 가며 RR Scheduling 방식으로 Switch가 일어나야 한다. 이를 위해 proc 구조체에 linked list를 이용해 구현한 queue를 `tl` (thread list)라는 이름으로 할당해 주었다.



Process Context Switch가 일어난 이후 다시 자신의 차례가 돌아왔을 때, Process는 이전에 마지막으로 동작했던 Thread를 기억하고 있어야 한다. 이를 위해 `proc` 구조체에 마지막으로 동작한 Thread의 q_node를 가리키고 있는 포인터 변수인 `t_node`가 필요했다.



Process Context Switch와 Thread Context Switch를 구별하기 위해, `tyield()`와 `tsched()`를 구현하였다. `tsched()`의 동작을 간단하게 설명하자면, 현재 `t_node`가 zombie가 아니라면 `proc->tl`에 push하고, `proc->tl`에서 pop한 thread로 context switch를 실행한다. 이때 pop한 thread의 `tstate`가 SLEEPING이라면 RUNNABLE인 thread가 나올 때까지 push 후 다시 pop을 실행하도록 하였다.

```c
void
tsched(void)
{
  struct proc *curproc = myproc();
  struct thread *curthread = mythread();
  struct q_node *newt_node, *oldt_node;

  if(curproc->nrt < 0){
    panic("nrt less than 1");
  }
  else if (curproc->nrt == 1 && curthread->tstate == RUNNABLE) 
  				//if nrt is 1, does not need to switch thread
  {
    return;
  }
  
  oldt_node = curproc->t_node;
  newt_node = queue_pop(&curproc->tl);
  while(newt_node->thread->tstate != RUNNABLE)
  {
    queue_push(&curproc->tl, newt_node);
    newt_node = queue_pop(&curproc->tl);
  }

  if(oldt_node->thread->tstate != ZOMBIE)
    queue_push(&curproc->tl, oldt_node);
  curproc->t_node = newt_node;
  mycpu()->ts.esp0 = (uint)newt_node->thread->kstack + KSTACKSIZE;
  swtch(&oldt_node->thread->context, newt_node->thread->context);
}
```
`tyield()`는 `tsched()`의 wrapper에 불과하다. lock이 acquire되지 않은 상황에서 `tsched()`를 호출하기 위해서는 `tyield()`를 호출하여야 한다. (ex. in `trap()`)

```c
void
tyield(void)
{
  acquire(&ptable.lock);  //DOC: yieldlock
  tsched();
  release(&ptable.lock);
}
```



### Thread 구조체를 위한 전반적인 System(+Systemcalls) Optimization 

- `proc.c`
- `vm.c`
- `sysfile.c`

쉽게 생각하면, 기존의 `proc`의 `kstack`, `tf`, `chan`, `context` 에 접근하는 대부분의 코드에 대해 최적화가 진행되어졌다. 

또한 현재 동작중인 thread 구조체를 쉽게 가져오기 위해, `myproc()`과 같은 원리로 `mythread()`를 구현하였다.

```c
struct thread*
mythread(void) {
  struct cpu *c;
  struct thread *t;
  pushcli();
  c = mycpu();
  t = c->proc->t_node->thread; // get current runnig process's current runnig thread
  popcli();
  return t;
}
```



#### Sleep & Wake

Sleep에 있어서 최하위 동작 단위가 Process에서 Thread로 바뀌었기 때문에, Sleep의 주체 또한 Thread로 변경되었다. 기본적으로 Sleep을 호출하면 현재 Thread의 `tstate`가 SLEEPING이 되고, `tsched()`를 호출하여 실행 권한을 다음 thread에게 넘겨주게 된다. 만약 현재 Process의 Thread가 자기 자신뿐이거나, 모두 SLEEPING이라면 현재 프로세스의 `state` 또한 SLEEPING으로 변형해준 후 `sched()`를 호출해 다른 프로세스에게 실행 차례를 양도한다.

```c
void
sleep(void *chan, struct spinlock *lk)
{
  //...  
  t->chan = chan;
  t->tstate = SLEEPING;
  p->nrt--;
  
  if(p->nrt > 0)
    goto threadsched;
  
  p->state = SLEEPING;
  sched();
  if(t->tstate == SLEEPING)
    goto threadsched;

  // Tidy up.
  t->chan = 0;

  // Reacquire original lock.
  if(lk != &ptable.lock){ 
    release(&ptable.lock);
    acquire(lk);
  }
  return;

threadsched:
  
  tsched();
  //...
}
```

`sched()` 이후 현재 thread의 `tstate`를 확인하는 코드는, `wakeup1()`으로 깨어난 thread가 현재 thread가 아닌 다른 thread인 경우를 확인해 주는 것이다. 

*(ex. 2번 thread가 chan 1에서 잠들고, 1번 thread가 chan 2에서 잠들었는데 chan 1이 먼저 wakeup된 경우 등)*



`wakeup1()`에서는 chan이 일치하는 thread의 `tstate`를 RUNNABLE로 변경해준 후, 해당 thread가 속한 process의 `state`또한 확인하여 SLEEPING인 경우 RUNNABLE로 변경해 준다.

```c
static void
wakeup1(void *chan)
{
  struct thread *t;
  for(t = ptable.thread; t < &ptable.thread[NTHREAD]; t++)
  {
    if(t->tstate == SLEEPING && t->chan == chan)
    {
      t->tstate = RUNNABLE;
      t->master->nrt++;
      if(t->master->state == SLEEPING)
        t->master->state = RUNNABLE;
    }
  }
}
```



#### Fork & Exec

기본적으로 변경된 설계에서는 `allocproc()`에서 UNUSED 상태인 `proc` 구조체와 `thread`구조체를 찾아, 필요한 값을을 할당한 후 thread를 process와 연결시켜준다.



Fork에서는 새로운 UNUSED proc과 thread를 찾아 할당한 후, 기존 proc의 `pgdir`과  현재 thread(현재 curproc의 t_node가 가리키고 있는 thread)만을 복사해 준다. 이후 기존의 proc의 queue에 들어 있던 실행 중이지 않은 thread들이 차지하고 있던 메모리 공간의 할당을 해제해 주는 동작을 수행한다.

```c
int
fork(void)
{
  //...생략...
  if((np = allocproc()) == 0){
    return -1;
  }
  nt = np->t_node->thread;

  // pgdir의 복제
  if((np->pgdir = copyuvm(curproc->pgdir, curproc->sz)) == 0){
    //...생략...
  }

  //...생략...
	
  // 새로운 프로세스의 bl에 현재 프로세스의 bl을 복제
  for(int i = 0; i < curproc->bl.cnt; i++){
    np->bl.blanklist[i] = curproc->bl.blanklist[i];
  }
  np->bl.cnt = curproc->bl.cnt;

  // 현재 프로세스를 제외한 나머지 프로세스가 차지하던 메모리 해제
  for(temp = curproc->tl.next; temp != 0; temp = temp->next){
    np->bl.blanklist[np->bl.cnt++] = temp->thread->tsb;
    deallocuvm(np->pgdir, temp->thread->tsb + 2*PGSIZE, temp->thread->tsb);
  }

  //...생략...
}
```



Exec에서는 유저 메모리를 모두 초기화하고, 실행할 대상을 위해 새로 구성해 주기 때문에 기존과 큰 차이는 없다.

다만 현재 프로세스에 여러 스레드가 있을 경우, 현재 thread(t_node가 가리키고 있는)를 제외한 모든 thread들을 해제시켜 주는 동작이 추가되었다.

```c
int
exec(char *path, char **argv)
{
  //...생략...
    
  curproc->nrt = 1;
  curproc->nt = 1;
  
  // queue에 남아있는 모든 thread 해제
  for(temp = queue_pop(&curproc->tl); temp != 0; temp = queue_pop(&curproc->tl)){
    kfree(temp->thread->kstack);
    temp->thread->kstack = 0;
    temp->thread->tf = 0;
    temp->thread->master = 0;
    temp->thread->tsb = 0;
    temp->thread->tstate = UNUSED;
    temp->thread->tid = 0;
    temp->thread->ret_val = 0;
    temp->thread->context = 0;
    temp->thread->chan = 0;
  }
  //...생략...
}
```



#### Kill & Exit

Thread를 따로 구현하여 proc에 속하게 하였기 때문에 Kill의 경우 별다른 변경 사항은 없다. 다만 실행 단위가 Thread로 바뀌었기 때문에, killed process에 `nrt`(number of runnable thread)가 0인 경우 해당 프로세스의 스레드 하나를 wakeup하여 `trap`에서 `exit()`이 호출되도록 강제하였다.

```c
int
kill(int pid)
{ 
  struct proc *p;
  acquire(&ptable.lock);
  for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
    if(p->pid == pid){
      p->killed = 1;
      if(p->nrt == 0) //nrt가 0인경우 아무런 프로세스를 깨워 trap에서 조건문에 걸리게 만들었다.
      {
        p->nrt++;
        p->t_node->thread->tstate = RUNNABLE; //가장 overhead가 적도록 최근의 thread를 깨움
      }
      release(&ptable.lock);
      return 0;
    }
  }
  release(&ptable.lock);
  return -1;
}
```



Exit은 특별한 변경이 없다. 다만 `wait()`을 주목해야 하는 점은, ZOMBIE process의 처리를 `wait()`에서 하고, 자식이 있는 상태에서 `wait()` 호출을 하지 않는 것은 **User Mistake**로 간주하기 때문이다. 따라서 ZOMBIE process에 속한 thread들의 해제 또한 `wait()`에서 처리해 주도록 코드를 변경하였다. 

*(User가 wait를 하지 않고 종료하더라도 initproc에서 wait을 통해 zombie process를 처리해 주게 되므로 wait에 구현하여도 무방하다)*

```c
int
wait(void)
{
  //...생략...
  for(;;){
    // Scan through table looking for exited children.
    havekids = 0;
    for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
      if(p->parent != curproc)
        continue;
      havekids = 1;
      if(p->state == ZOMBIE){
		// thread 할당 해제
        for(tempnode = p->t_node; tempnode != 0; tempnode = queue_pop(&p->tl)){
          tempt = tempnode->thread;
          kfree(tempt->kstack);
          tempt->master = 0;
          tempt->context = 0;
          tempt->chan = 0;
          tempt->tf = 0;
          tempt->tsb = 0;
          tempt->tstate = UNUSED;
          tempt->tid = 0;
          tempt->kstack = 0;
        }

        // proc 할당 해제
        pid = p->pid;
        freevm(p->pgdir);
        p->pid = 0;
        p->parent = 0;
        p->name[0] = 0;
        p->killed = 0;
        p->bl.cnt = 0;
        p->sz = 0;
        p->t_node = 0;
        p->nrt = 0;
        p->state = UNUSED;
        release(&ptable.lock);
        return pid;
      }
    }

    //...생략...
  }
}
```



#### Sbrk

Sbrk의 경우 Proc이라는 단위를 그대로 두고 `sz` 값을 `proc` 구조체에 그대로 유지한 설계로 인해 큰 변경사항은 없으나, 여러 thread에서 `sbrk()`를 호출했을 때 race condition의 발생을 예방하기 위해 `growlock`을 만들어 acquire하도록 하였다. `growproc()` 이 아닌 `sbrk()` 에서 lock을 잡는 이유는 `growproc()`에서 lock을 잡을 경우 `sbrk()`에서 `sz` 값을 로드한 이후 `growproc()` 호출 직전에 timer interrupt 가 발생하여 다른 thread에서 `sbrk()`를  호출할 경우 `addr`은 같은 곳을 가리키지만, 실제 할당된 공간은 다를 수 있기 때문이다.

```c
int
sys_sbrk(void)
{
  //...생략...
  // acquire growlock to prevent race condition from multithread sbrk calls
  acquire(&growlock);
  addr = myproc()->sz;
  if(growproc(n) < 0)
  {
    release(&growlock);
    return -1;
  }
  release(&growlock);
  return addr;
}
```

`growlock()`의 `initlock()`은 `pinit()` 호출 시 `ptable.lock`의 init과 함께 처리해 주었다.

- *참고사항이지만, `sbrk()`와 `thread_create()`와의 **memory allocation conflict**를 방지하기 위해 `thread_create()`에서 thread stack을 할당하는 부분에서도 growlock을 취득한다.*



### LWP Basic Operations (Create, Exit, Join)

#### thread_create

`thread_create()`의 코드 구성은 두 파트로 나눌 수 있다.

- *(fork와 비슷한)* 새로운 thread를 할당하고 기존 process에 연결하는 부분
- *(exec과 비슷한)* 새로운 thread에 실행할 start_routine을 설정해주는 부분

이때 새로운 thread를 생성할 때, proc의 blanklist를 확인하여 메모리의 중간에 빈 공간이 있다면 해당 공간을 새로운 thread의 stack으로 할당하게 된다.

```c
int
thread_create(thread_t* thread, void* (*start_routine)(void *), void* arg)
{
  //...생략... (fork와 비슷한 동작 수행)
  // 현재 프로세스의 메모리에서 빈 stack 공간이 있는지 확인하여 사용
  if(curproc->bl.cnt == 0)
  { // 없으면 sz 증가시켜 사용
    sz = curproc->sz;
    curproc->sz += 2*PGSIZE;
  }
  else
  {
    curproc->bl.cnt--;
    sz = curproc->bl.blanklist[curproc->bl.cnt];
  }

  //...생략... (exec과 비슷한 동작 수행)
}
```



#### thread_exit

`thread_exit()`에서는 현재 thread를 종료시켜 ZOMBIE로 만들고, 만약 현재 thread가 현재 process의 마지막 thread였다면 `exit()`을 호출하고, 이외에 다른 thread가 있으나 모두 SLEEPING인 경우 현재 process를 SLEEPING으로 변경한 후 `sched()`를 호출하게 된다.

```c
void 
thread_exit(void* retval)
{
  struct proc *curproc;
  struct thread *curthread;
  acquire(&ptable.lock);
  curproc = myproc();
  curthread = mythread();

  curproc->nt--;
  curproc->nrt--;
  if(curproc->nt < 1)  // this was last thread...
  {
    cprintf("last thread called thread_exit\n");
    release(&ptable.lock);
    exit();
  }

  curthread->ret_val = retval;
  curthread->tstate = ZOMBIE;

  wakeup1(curproc);

  while(curproc->nrt < 1) //nrt가 0인데 nt는 0이 아니라면 SLEEPING인 thread가 존재한다는 의미
  {
    curproc->state = SLEEPING;
    sched();
  }
  tsched();
  panic("zombie thread exit");
}
```



#### thread_join

기본적인 동작 방식은 `wait()`과 매우 흡사하다. 해당 `tid`를 지닌 thread를 찾아 종료될 때 까지 sleep하고, 종료되면 해당 thread의 retval을 가져온 후 해당 thread의 할당을 해제시켜준다.

```c
int
thread_join(thread_t thread, void** retval)
{
  struct thread *t;
  struct proc *curproc = myproc();
  int havethreads = 0;
  
  acquire(&ptable.lock);

  for(;;){
    havethreads = 0;
    for(t = ptable.thread; t < &ptable.thread[NTHREAD]; t++){
      if(t->tid != thread)
        continue;
      havethreads = 1;
      if(t->tstate == ZOMBIE){
        *retval = t->ret_val;
        kfree(t->kstack);
        t->kstack = 0;
        t->tstate = UNUSED;
        t->master->bl.blanklist[t->master->bl.cnt] = t->tsb;
        t->master->bl.cnt++;
        deallocuvm(t->master->pgdir, t->tsb + 2*PGSIZE, t->tsb);
        t->master = 0;
        release(&ptable.lock);
        return 0;
      }
    }

    // No point waiting if we don't have any threads.
    if(!havethreads || curproc->killed){
      release(&ptable.lock);
      return -1;
    }
    // Wait for thread to exit.  (See wakeup1 call in proc_exit.)
    sleep(curproc, &ptable.lock);  
  }
  release(&ptable.lock);
  return 0;
}
```





### Other Corner Cases

기본적인 예외 사항들은 처리가 되어져 있다. 다만 아직까지 해결하지 못한 것은 `sbrk()`의 동작에 있어서 예외사항이다. 

 `sbrk()`는 현재 프로세스의 `sz` 값을 가져와  `growproc()` 을 수행하는데, 만약 `sbrk()` 호출 후 그 위에 새로운 thread의 stack이 할당된다면, `sz`는 새로 할당된 stack의 제일 윗부분을 가리키고 있으므로 `sbrk()`를 이용한 할당 해제가 불가능해진다. 



시스템 설계상으로 이를 해결하기 위해서는 proc에 새로운 변수를 할당하여 user가 `sbrk()`를 통해 사용하는 공간과 thread의 stack이 추가되는 공간을 분리해야한다. 다만 이렇게 되면 User memory에 또 하나의 공간 분리를 발생시켜야 하는데, 전체적인 흐름에 있어서 User memory의 구조는 아직 내가 알지 못하는 부분까지도 영향을 미칠 수 있기 때문에 구현하지는  않았다. *- 관련된 내용은 Issues의 "[sbrk & thread_create conflict](https://hconnect.hanyang.ac.kr/2021_ele3021_12873/2021_ele3021_2017030246/-/issues/1)" 참고*



대신 이는 사용자에게 주의를 요하게 하여, `sbrk()`호출이 필요한 경우 필요한 최대 thread까지 생성한 후 호출한다면 문제를 예방할 수 있다. 

*(ex. 프로그램이 최대 20개의 스레드를 사용하는 경우, 20개까지 생성 후 sbrk를 호출하면, 이후에는 20개의 한도 내에서는  thread_exit과 thread_create가 sbrk에 영향을 끼치지 않는다. 이는 thread_create가 기존에 사용했지만 현재 비어있는 stack 공간을 활용하기에, proc->sz에 더이상 변화를 주지 않기 때문이다. )*

